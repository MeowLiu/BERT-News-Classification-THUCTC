# 📰 BERT-NEWS-CLASSIFICATION-THUCTC  
*中文新闻分类系统 · BERT/RoBERTa 微调 · 端到端部署*

> **🎯 项目目标**  
> 基于中文优化版 BERT/RoBERTa 模型，在 THUCNews 数据集构建**高精度新闻分类系统**，集成 FastAPI + React 前后端，实现文本自动分类与可视化。

---

## 🚀 项目进度看板

| 状态       | 任务                          | 详情/进度               |
|------------|-------------------------------|-------------------------|
| ✅ **完成** | 项目初始化                    | 目录结构搭建完成        |
| ✅ **完成** | THUCNews 数据集全量导入       | **836,074** 有效文档 (14类) |
| ✅ **完成** | 数据清洗与预处理              | 94.2% 有效保留率        |
| ✅ **完成** | 数据标准化                    | 分词/停用词过滤         |
| ✅ **完成** | 数据分析                    | 统计文本信息与分析         |
| ✅ **完成** | 环境配置                      | Python 3.10 + PyTorch   |
| ✅ **完成** | 数据增强                      |数据增强30% ，缓解了类别不平衡问题 |
| ✅ **完成** | React+TypeScript构建前端      |   预先搭建了美观可运行前端 |
| ✅ **完成** | 训练朴素贝叶斯   | 利用分类器进行文本分类，发现了数据增强的一些问题 |
| ✅ **正在进行** | 训练SVM分类器   | 利用分类器进行文本分类，并最终与BERT比较 |
| 🔴 **待启** | BERT微调训练：增强与未增强之间的对比                 | 预计 2025-12-10 启动    |
| 🔴 **待启** | RoBERTa 微调训练                 | 预计 2025-12-10 启动    |
| 🔴 **待启** | FastAPI构建后端               | 预计 2025-12-10 启动    |

---

## 📊 全量数据报告

### 📥 数据提取统计 (14/14 类别)
| **指标**       | **值**               | **指标**         | **值**          |
|----------------|----------------------|------------------|-----------------|
| **执行窗口**   | 20:06 ~ 21:20        | **总耗时**       | 1小时14分钟     |
| **总文档数**   | 836,074              | **平均速度**     | 158.5 文件/秒   |
| **空文件过滤** | 14                   | **最大类别**     | 科技 (162,929)  |
| **数据分布**   |                      |                  |                 |
| **头部3类** 🥇 | **尾部3类** 🥉       |                  |                 |
| 科技 (19.5%)   | 星座 (0.4%)          |                  |                 |
| 股票 (18.5%)   | 彩票 (0.9%)          |                  |                 |
| 体育 (15.7%)   | 时尚 (1.6%)          |                  |                 |

### 📈 完整类别统计
| 排名 | 类别 | 有效文件数 | 速度(文件/秒) | 耗时   | 占比  |
|------|------|------------|---------------|--------|-------|
| 1    | 科技 | 162,929    | 178.68        | 15m11s | 19.5% |
| 2    | 股票 | 154,398    | 158.83        | 16m12s | 18.5% |
| 3    | 体育 | 131,603    | 161.68        | 13m33s | 15.7% |
| 4    | 娱乐 | 92,632     | 155.08        | 9m57s  | 11.1% |
| 5    | 时政 | 63,086     | 151.65        | 6m56s  | 7.5%  |
| 6    | 社会 | 50,849     | 156.21        | 5m25s  | 6.1%  |
| 7    | 教育 | 41,936     | 152.71        | 4m34s  | 5.0%  |
| 8    | 财经 | 37,098     | 150.31        | 4m06s  | 4.4%  |
| 9    | 家居 | 32,586     | 153.04        | 3m32s  | 3.9%  |
| 10   | 游戏 | 24,373     | 152.09        | 2m40s  | 2.9%  |
| 11   | 房产 | 20,050     | 161.25        | 2m04s  | 2.4%  |
| 12   | 时尚 | 13,368     | 149.78        | 1m29s  | 1.6%  |
| 13   | 彩票 | 7,588      | 148.93        | 50s    | 0.9%  |
| 14   | 星座 | 3,578      | 151.51        | 23s    | 0.4%  |

> **💡 关键洞察**  
> 1. **头部垄断**：科技+股票+体育占总量 **53.7%**，需警惕模型偏向  
> 2. **长尾挑战**：最小3类（星座/彩票/时尚）仅占 **2.9%**，需过采样策略  
> 3. **IO瓶颈**：股票类处理最慢（158.83 文件/秒），因单文件体积较大  

## 🧹 预处理效果
| **阶段**         | **数据量** | **变化率** | **关键操作**               |
|------------------|------------|------------|----------------------------|
| 原始数据         | 836,088    | 100%       | 14个类别目录               |
| **清洗后有效数据** | **787,500**| **94.1%**| 过滤48,574个过短或过长文件           |
| **数据集划分**   |            |            |                            |
| - 训练集 (70%)   | 585,252    | 🔴 高优先级 |                            |
| - 验证集 (15%)   | 125,411    | 🟠 中优先级 |                            |
| - 测试集 (15%)   | 125,411    | 🟠 中优先级 |                            |


## 🔍 原始数据 vs 清洗后对比

### 📝 典型样本对比
| **原始数据 (Raw)** | **清洗后数据 (Cleaned)** |
|--------------------|--------------------------|
| ```体育马晓旭意外受伤让国奥警惕 无奈大雨格外青睐殷家军\n　　记者傅亚雨沈阳报道 来到沈阳，国奥队...``` | ```体育马晓旭 意外 受伤 国奥 警惕 无奈 大雨 青睐 殷家 军 傅亚雨 沈阳 报道 来到 沈阳 ...``` |
| ```体育揭秘谢亚龙被带走：总局电话骗局 复制南杨轨迹\n　　体坛周报特约记者张锐北京报道  谢亚龙已..``` | ```体育揭秘 谢亚龙 带走 总局 电话 骗局 复制 南杨 轨迹 体坛周报 特约记者 张锐 北京 报道...``` |

**性能指标**  
⏱️ 总耗时：**1小时14分** | ⚡ 峰值速度：**178.68 文件/秒** (科技类) | 💾 最终输出：`data/THUCNews.csv` (836,074条)

## 📊 中文新闻数据集详细统计分析报告

> **概览**：
> * **总新闻数**：787,500 条
> * **类别总数**：14 类
> * **平均字符数**：446.9 字
> * **数据不平衡度**：44.31:1 (极度不平衡)

---

### 1. 📏 基本统计信息
此表展示了各类别的数据规模及文本长度（字符与词数）的均值与中位数。

| 类别 | 新闻数 | 平均字符 | 中位字符 | 平均词数 | 中位词数 |
| :--- | :---: | :---: | :---: | :---: | :---: |
| **财经** | 33,594 | **576.9** | **561.0** | **271.9** | **264.0** |
| **社会** | 46,330 | 542.9 | 483.0 | 261.5 | 232.0 |
| **体育** | 125,673 | 534.2 | 496.0 | 248.8 | 231.0 |
| **教育** | 36,385 | 529.0 | 471.0 | 241.7 | 216.0 |
| **房产** | 18,759 | 474.3 | 383.0 | 224.6 | 185.0 |
| **彩票** | 6,524 | 471.0 | 446.0 | 234.1 | 219.0 |
| **游戏** | 23,429 | 449.6 | 401.0 | 207.5 | 186.0 |
| **科技** | **153,043** | 436.9 | 370.0 | 196.0 | 166.0 |
| **股票** | 146,601 | 417.9 | 352.0 | 193.3 | 162.0 |
| **娱乐** | 88,937 | 412.0 | 339.0 | 193.7 | 159.0 |
| **时政** | 60,683 | 357.7 | 283.0 | 159.9 | 126.0 |
| **时尚** | 13,185 | 350.5 | 284.0 | 166.8 | 136.0 |
| **家居** | 30,903 | 350.4 | 211.0 | 163.8 | 99.0 |
| **星座** | 3,454 | 353.4 | 145.0 | 169.6 | 70.0 |

---

### 2. 📉 字符长度分布
展示文本长度的分布情况，有助于了解是否存在异常短文本或超长文本。

| 类别 | 最小值 | Q25 (下四分位) | 中位数 | Q75 (上四分位) | 最大值 | 标准差 |
| :--- | :---: | :---: | :---: | :---: | :---: | :---: |
| **体育** | 17 | 331 | 496 | 698 | 1427 | 278.7 |
| **娱乐** | 12 | 210 | 339 | 545 | 1524 | 269.9 |
| **家居** | 7 | 71 | 211 | 562 | 1435 | 339.7 |
| **彩票** | 14 | 159 | 446 | 718 | 1410 | 326.6 |
| **房产** | 8 | 300 | 383 | 586 | 1375 | 267.3 |
| **教育** | 10 | 269 | 471 | 742 | **1696** | 331.3 |
| **时尚** | 10 | 169 | 284 | 467 | 1440 | 252.0 |
| **时政** | 15 | 192 | 283 | 444 | 1473 | 251.8 |
| **星座** | 16 | 91 | 145 | 560 | 1367 | **347.5** |
| **游戏** | 9 | 259 | 401 | 582 | 1569 | 257.2 |
| **社会** | 18 | 310 | 483 | 731 | 1457 | 293.9 |
| **科技** | 7 | 238 | 370 | 562 | 1495 | 278.2 |
| **股票** | 7 | 166 | 352 | 606 | 1450 | 301.7 |
| **财经** | 8 | 308 | **561** | **799** | 1402 | 324.4 |

---

### 3. 🗝️ 各类别高频词云 (Top 10)
为了节省篇幅并便于对比，将各类别的前 10 高频词整理如下：

| 类别 | 核心关键词 (按词频降序) |
| :--- | :--- |
| **⚽ 体育** | 比赛, 中, 球员, 球队, 说, 时间, 赛季, 新浪, 分钟, 中国 |
| **🎬 娱乐** | 说, 中, 娱乐, 新浪, 讯, 电影, 做, 北京, 观众, 导演 |
| **🏠 家居** | 产品, 企业, 家具, 品牌, 市场, 中国, 家居, 消费者, 中, 行业 |
| **🎫 彩票** | 期, 号码, 号, 中, 注, 开出, 双色球, 主场, 胜, 平 |
| **🏙️ 房产** | 项目, 平米, 户型, 北京, 元, 楼盘, 开发商, 万, 信息, 均价 |
| **🎓 教育** | 考生, 学生, 高考, 考试, 招生, 录取, 专业, 中, 学校, 信息 |
| **👗 时尚** | 搭配, 中, 吃, 女性, 减肥, 时尚, 组图, 穿, 导语, 身体 |
| **📰 时政** | 说, 美国, 中, 报道, 中国, 国家, 总统, 称, 日电, 政府 |
| **🔮 星座** | 爱情, 星座, 测试, 说, 中, 心理, 图, 爱, 喜欢, 朋友 |
| **🎮 游戏** | 游戏, 玩家, 中, 活动, 网游, 新, 世界, 系统, 中国, 体验 |
| **👀 社会** | 说, 中, 岁, 警方, 发现, 民警, 医院, 孩子, 称, 元 |
| **📱 科技** | 元, 手机, 用户, 中, 公司, 市场, 采用, 中国, 产品, 网络 |
| **📈 股票** | 市场, 公司, 点, 经济, 中, 中国, 增长, 上涨, 亿元, 板块 |
| **💰 财经** | 基金, 市场, 公司, 投资, 期货, 中, 元, 价格, 上涨, 美元 |

---

### 💡 数据分析总结与洞察
#### 1. ⚠️ 严重的数据不平衡
* **现象**：数据集存在极端的类别不平衡。头部类别**科技** (15.3万) 和 **股票** (14.6万) 的数据量远超尾部类别。
* **对比**：最多的“科技”类是最少的“星座”类 (3,454) 的 **44 倍**。
* **建议**：在进行模型训练（如分类任务）时，必须采取**过采样 (Oversampling)**、**欠采样 (Undersampling)** 或使用 **Focal Loss** 等策略，否则模型将极度偏向预测为科技、股票或体育类。

#### 2. 📝 文本长度差异明显
* **长文本类**：**财经、社会、教育、体育**。这些类别的平均长度都在 500 字以上，中位数也较高，说明内容多为深度报道、赛事详述或政策解析。
* **短文本类**：**家居、时尚、星座**。尤其是星座类，中位数仅 145 字符，Q25 甚至只有 91 字符，说明该类别包含大量短句、运势摘要或以图片为主的内容（关键词中包含“组图”）。

#### 3. 🔍 关键词特征分析
* **停用词残留**：虽然进行了清洗，但“说”、“中”、“称”等词在多个类别（娱乐、体育、时政、社会）中依然高频出现。这表明可以进一步优化停用词表，去除这些对分类贡献度较低的通用动词。
* **语义重叠与区分**：
    * **强区分度**：教育（考生/高考）、彩票（双色球/注）、房产（户型/平米）的特征词非常独特，分类难度预计较低。
    * **潜在混淆**：
        * **股票 vs 财经**：两者都高频出现“市场”、“公司”、“上涨”。区别在于股票侧重“点”、“板块”，财经侧重“基金”、“期货”。
        * **科技 vs 家居**：都关注“产品”、“市场”、“品牌”。

#### 4. 🌏 内容地缘与实体
* **时政类**：高频词包含“美国”、“总统”，显示该数据集的国际新闻占比较大，或中美关系是报道重点。
* **地域性**：娱乐和房产类中，“北京”高频出现，暗示数据源（新浪新闻）可能以北京地区的报道或总部采编为主。

## 📊 THUCNews 数据增强分析报告

### 1. 总体概况 (Overview)

本次数据增强旨在解决长尾分布问题，通过 **BERT 上下文增强** 与 **随机删除** 相结合的策略，对尾部类别进行了补充。

| 指标 | 数值 | 备注 |
| :--- | :--- | :--- |
| **原始样本总数** | 787,500 | |
| **增强后总数** | **1,024,937** | |
| **新增样本数** | **+237,437** | 约为原始数据的 30% |
| **目标阈值** | 50,000 | 尾部类别补齐至此数量 |
| **数据集划分**   |            |            |                            |
| - 训练集 (70%)   | 717455     | 🔴 高优先级 |                            |
| - 验证集 (15%)   | 153741     | 🟠 中优先级 |                            |
| - 测试集 (15%)   | 153741    | 🟠 中优先级 |    
---

### 2. 类别不平衡优化 (Imbalance Optimization)

通过增强，类别不平衡问题得到了显著改善，模型训练的公平性将大幅提升。

* **原始类别不平衡度 (Max/Min):** `44.31` (科技 vs 星座)
* **当前类别不平衡度 (Max/Min):** `3.06` (科技 vs 星座/彩票等)
* **优化效果:** 不平衡度降低了 **93%**。

---

### 3. 详细分布表 (Detailed Distribution)

以下表格展示了增强前后的数量对比，以及新增数据的来源构成（BERT生成 vs 随机删除）。

> **注**：头部类别（数量 > 50,000）保持原样，未进行增强。

| 类别 | 原始数量 (Original) | 增强后数量 (Augmented) | 总增长 (Growth) | 增强构成 (Composition) |
| :--- | :--- | :--- | :--- | :--- |
| **星座** | 3,454 | **50,000** | +46,546 | BERT: 13,963 / Del: 32,583 |
| **彩票** | 6,524 | **50,000** | +43,476 | BERT: 13,042 / Del: 30,434 |
| **时尚** | 13,185 | **50,000** | +36,815 | BERT: 11,044 / Del: 25,771 |
| **房产** | 18,759 | **50,000** | +31,241 | BERT: 9,372 / Del: 21,869 |
| **游戏** | 23,429 | **50,000** | +26,571 | BERT: 7,971 / Del: 18,600 |
| **家居** | 30,903 | **50,000** | +19,097 | BERT: 5,729 / Del: 13,368 |
| **财经** | 33,594 | **50,000** | +16,406 | BERT: 4,921 / Del: 11,485 |
| **教育** | 36,385 | **50,000** | +13,615 | BERT: 4,084 / Del: 9,531 |
| **社会** | 46,330 | **50,000** | +3,670 | BERT: 1,101 / Del: 2,569 |
| **时政** | 60,683 | 60,683 | 0 | - |
| **娱乐** | 88,937 | 88,937 | 0 | - |
| **体育** | 125,673 | 125,673 | 0 | - |
| **股票** | 146,601 | 146,601 | 0 | - |
| **科技** | 153,043 | 153,043 | 0 | - |

---

### 4. 增强策略总结 (Strategy Summary)

针对需要增强的 9 个尾部类别，采用了混合增强策略：

1.  **BERT 上下文增强 (~30%)**: 生成了高质量、语义连贯的新样本，确保模型学习到更丰富的特征表达。
2.  **随机删除 (~70%)**: 通过模拟噪声输入，防止模型对因重复采样导致的过拟合，同时保证了数据处理的高效率。

**结论**: 数据集结构已从极度长尾分布调整为相对均衡分布，可直接用于后续的模型训练。


## THUCTCNews 朴素贝叶斯新闻分类实验结果深度分析报告

### 1. 实验总体概述

本实验基于朴素贝叶斯（Naive Bayes）算法对 THUCTCNews 数据集进行文本分类。实验旨在探究数据增强（Data Augmentation）技术对模型性能的影响。实验共设置了三个对照组：
1.  **基准实验**：使用原始数据集进行训练和测试。
2.  **全量增强实验**：对训练集和测试集均进行了数据增强（主要用于验证测试集分布对评估的影响）。
3.  **修正增强实验**：仅对训练集进行增强，保持测试集为原始分布（符合真实应用场景）。

### 2. 实验结果对比与详细分析

#### 2.1 核心指标对比

| 实验组别 | 准确率 (Accuracy) | Weighted F1 | 备注 |
| :--- | :--- | :--- | :--- |
| **基准 (Baseline)** | **0.9186** | **0.9187** | 原始数据，表现最佳 |
| **全量增强 (Train+Test)** | 0.7616 | 0.7600 | 测试集被人为修改，不可信 |
| **修正增强 (Train Only)** | 0.9157 | 0.9155 | 仅训练集增强，效果略微下降 |

#### 2.2 现象分析：为什么“增强训练集+原始测试集”反而效果下降？

对比基准结果（0.9186）和修正增强结果（0.9157），我们发现引入数据增强后，模型性能并没有提升，反而出现了轻微的下滑（约 0.3%）。这在朴素贝叶斯模型中是值得注意的现象，主要原因分析如下：

1.  **小样本类别的 Precision/Recall 权衡偏移**：
    * **观察**：重点观察小样本类别，如“星座”（Support: 596）和“彩票”（Support: 1038）。
        * *基准*：星座 F1=0.93 (P=0.94, R=0.92)；彩票 F1=0.92 (P=0.96, R=0.89)。
        * *增强后*：星座 F1=0.75 (P=0.99, **R=0.61**)；彩票 F1=0.85 (P=0.98, **R=0.75**)。
    * **分析**：数据增强（推测使用了过采样或同义词替换）显著提高了这些类别的**查准率（Precision）**，但严重牺牲了**查全率（Recall）**。
    * **原因**：朴素贝叶斯对特征的条件概率非常敏感。如果增强方法（如简单的重复过采样）只是增加了特定词汇的频率，模型会变得对这些词汇“过拟合”，导致只有包含这些强特征的样本才会被预测为该类，从而漏掉了变体较多的真实样本，导致 Recall 大幅下降。

2.  **噪声引入与独立性假设**：
    * 朴素贝叶斯基于“特征独立性假设”。如果使用的数据增强方法（如 EDA 中的随机插入、交换）破坏了文本原本的语序或引入了在该类别中本不该出现的高频噪声词，会直接干扰贝叶斯概率的计算，导致分类边界模糊。

#### 2.3 现象分析：测试集增强的陷阱 (Accuracy 0.7616)

你提到的“把测试集也增强了”导致结果大幅下降，这是毕业设计中一个极佳的反面教材案例（Failure Analysis）：

* **分布不一致 (Distribution Shift)**：测试集的目的是模拟真实世界的数据分布。如果你对测试集进行了平衡化处理（从 Support 列表看，各类别变成了 7500 条左右），你实际上改变了测试任务的难度。原始数据中“科技”类有 23000 条，模型倾向于预测大类；强制平衡测试集后，模型原本对大类的先验概率优势荡然无存，导致整体准确率崩塌。
* **合成数据质量**：如果增强生成的文本质量不高（语义不通顺），将其作为测试集，相当于让模型去预测“垃圾数据”，分数自然很低。

### 3. 数据增强在文本分类中的优缺点讨论

在撰写毕业设计时，可以基于上述结果总结以下优缺点：

#### 3.1 优点 (Pros)
1.  **缓解类别不平衡（Class Imbalance）**：
    * 通过对“星座”、“家居”等小样本类别进行过采样，可以在一定程度上防止模型完全忽略这些类别（虽然在本次朴素贝叶斯实验中表现为高 Precision 低 Recall，但在深度学习模型中通常能有效提升整体 F1）。
2.  **提升模型鲁棒性（仅限深度学习）**：
    * 对于 LSTM、BERT 等模型，数据增强带来的扰动能充当正则化项，防止过拟合。
3.  **扩展决策边界**：
    * 合理的增强（如回译、同义词替换）可以引入新的词汇组合，丰富模型的特征空间。

#### 3.2 缺点与局限性 (Cons)
1.  **可能引入噪声（Noise Injection）**：
    * 自动化的增强（如随机删除、替换）可能会破坏句子的核心语义，导致标签与内容不符（Label Noise）。
2.  **对朴素贝叶斯不友好**：
    * **关键点**：朴素贝叶斯是生成式模型，高度依赖词频统计。简单的数据增强（特别是重复采样）只是改变了先验概率 $P(Y)$ 和条件概率 $P(X|Y)$ 的数值，如果增强后的分布偏离了真实自然语言的统计规律，朴素贝叶斯的效果往往不如不增强。
3.  **计算成本增加**：
    * 训练数据量从 11万 增加到 15万+，增加了训练时间和内存开销。

### 4. 毕业设计中的注意事项 (Notices)

针对你的毕设，基于以上结果，建议在论文中补充以下讨论：

1.  **测试集的纯洁性 (Sanctity of Test Set)**：
    * **必须强调**：严禁触碰测试集。测试集必须代表真实的、未处理的原始分布。你在报告中展示的 Accuracy 0.7616 的结果，应作为“实验对照组”来论证为什么不能增强测试集，而不是作为模型性能差的证据。

2.  **模型与增强方法的匹配度**：
    * 分析指出：朴素贝叶斯可能不是数据增强的最佳受益者。如果时间允许，建议对比一个简单的深度学习模型（如 TextCNN 或 BiLSTM）。通常在深度模型上，数据增强（特别是针对小样本类别）会带来正向收益，这样可以形成鲜明的对比结论。

3.  **查全率（Recall）的断崖式下跌**：
    * 深入分析为什么“星座”类别的 Recall 从 0.92 跌至 0.61。这表明模型变得过于保守。可以检查一下增强后的数据，是否某些关键词被过度重复了？

4.  **结论建议**：
    * 结论不要只写“数据增强效果不好”。应该写：“在基于统计的朴素贝叶斯模型下，简单的数据增强干扰了特征的概率分布，导致小样本类别的召回率显著下降。这证明了数据增强技术需要与模型特性相匹配，对于强依赖统计规律的浅层模型，应谨慎使用破坏性增强。”

### 5. 总结

本次实验证明，**对于 THUCTCNews 数据集上的朴素贝叶斯分类器，原始数据已经包含了足够且规律的统计特征（Accuracy 91.86%）。** 盲目的数据增强（特别是可能改变了词频分布的增强）反而引入了干扰，导致模型在小样本类别上出现“高准确、低召回”的过拟合现象。未来的改进方向应集中在**特征工程**（如调整 TF-IDF 参数、去停用词）或**更换对特征交互理解更深的模型**（如 Deep Learning），而非单纯增加数据量。
### 6. 建议的后续步骤：
如果需要将这部分内容放入论文，建议画一个柱状图，对比 Baseline 和 Augmented (Train Only) 在“星座”、“房产”、“彩票”这几个变化大的类别上的 Precision 和 Recall，这样视觉冲击力更强，更能支撑你的论点。

## 针对类别不平衡处理的深入分析报告

### 1. 实验动机与背景
在原始 THUCTCNews 数据集中，类别分布呈现极端的长尾分布。最大类别（科技/股票）与最小类别（星座/彩票）的比例高达 **44:1**。
* **理论隐患**：在如此悬殊的比例下，传统的机器学习模型倾向于通过“忽略少数类”来获得全局最高的准确率（Accuracy）。模型可能会习得一个偏差：只要预测为大类，就有很大概率猜对。
* **改进措施**：本实验引入数据增强技术，将类别不平衡比从 **44:1** 降低至 **3:1**，旨在强迫模型更多地关注小样本类别特征。

### 2. 反常现象分析：为什么“平衡”反而伤害了模型？

尽管数据分布被优化到了 3:1，但实验结果显示，小样本类别的性能不升反降（以“星座”为例，Recall 从 0.92 降至 0.61）。这在朴素贝叶斯（Naive Bayes）模型中揭示了以下深层机制：

#### 2.1 先验概率（Prior）与后验概率的冲突
朴素贝叶斯的分类决策公式为：
$$\hat{y} = \arg\max_{y} P(y) \prod_{i=1}^{n} P(x_i | y)$$

* **原始状态（44:1）**：虽然 $P(y_{星座})$ 很小，但由于新闻文本特征（关键词）非常鲜明（如“水瓶座”、“运势”），$P(x|y)$ 这一项非常大，足够抵消先验概率的劣势。原始模型已经能够很好地捕捉这些强特征。
* **增强状态（3:1）**：
    * 我们人为提高了 $P(y_{星座})$（先验概率）。
    * **关键问题**：如果数据增强引入了**噪声**或**特征稀释**（Feature Dilution），那么 $P(x|y)$（似然概率）会显著下降。
    * **结果**：数据增强产生的合成样本可能包含了一些非典型的词汇，导致模型学习到的“星座类特征分布”变得更加宽泛和模糊。当模型面对测试集中那些“标准、干净”的原始样本时，反而因为特征匹配度（Likelihood）计算下降，导致置信度不足，从而漏检（Recall 下降）。

#### 2.2 过拟合增强数据（Overfitting to Augmented Data）
* **现象**：在“星座”类中，Precision 提升到了 0.99，但 Recall 降至 0.61。
* **解读**：模型变得**极其保守**。它现在的逻辑是：“除非这个样本长得非常像我训练集里那些增强过的特定样本，否则我就不认为它是星座。”
* 这说明数据增强可能产生了**分布偏移（Distribution Shift）**。训练集中的“星座”数据（原始+增强）的分布，已经与测试集中的“星座”数据（纯原始）产生了较大差异。朴素贝叶斯这种基于统计的浅层模型对这种分布变化非常敏感。

#### 2.3 “基准悖论”：原始数据其实并不差
* 回看 Baseline 结果，即使在 44:1 的不平衡下，星座的 F1 依然达到了 0.93。
* 这说明 THUCTCNews 数据集的一个特点：**文本特征的可区分性极强（Separability）**。新闻分类不同于复杂的语义分析，关键词（特征词）通常具有决定性作用。
* **结论**：对于特征区分度极高的数据集，类别不平衡并不是主要瓶颈。强行平衡数据反而破坏了原始数据中自然、干净的概率统计规律。

### 3. 毕业设计中的结论与建议

在论文中，你不应掩盖这一结果，而应将其升华为对**模型特性**的探讨：

1.  **模型适用性结论**：
    > 实验表明，朴素贝叶斯分类器高度依赖特征的统计独立性和原始概率分布。在特征区分度较高（High Separability）的文本分类任务中，该模型对类别不平衡具有较强的鲁棒性（Robustness）。盲目使用数据增强试图“矫正”分布，反而可能因引入噪声而破坏特征的条件概率分布，导致召回率下降。

2.  **对比论证（加分项）**：
    > 相比之下，深度学习模型（如 BERT 或 BiLSTM）通常更受益于 3:1 的平衡策略，因为它们需要大量数据来拟合复杂的决策边界，且容易陷入局部最优。而朴素贝叶斯是生成式模型，其参数估计直接来源于计数，对“虚假”的平衡数据更敏感。

3.  **最终陈述**：
    > 因此，针对本任务，**保留原始分布（或仅做轻微平衡）** 是比激进的数据增强（44:1 -> 3:1）更优的策略。数据增强并非“万金油”，其有效性取决于**模型结构**与**特征质量**的交互作用。
    
#### 论文逻辑链条应该是：

    > 发现问题：数据存在严重不平衡 (44:1)。
    
    提出假设：通过数据增强降低不平衡度 (3:1) 应该能提升模型性能，特别是小样本类别。

    实验验证：实施增强并测试。

    结果观测：总体准确率持平，但小样本类别 Recall 显著下降，Precision 极高。

    理论分析：这是因为朴素贝叶斯对特征分布的敏感性 + 数据增强引入的特征偏移 > 平衡先验概率带来的收益。

    结论：证明了朴素贝叶斯在处理高区分度文本时对不平衡的鲁棒性，反证了数据增强策略需要针对模型进行适配。